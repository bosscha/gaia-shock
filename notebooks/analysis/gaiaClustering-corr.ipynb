{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests\n",
    "Use of the agglomerative clustering with HR diagram.\n",
    "\n",
    "We test here the 2D correlation function to detect cluster in the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../../src')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from math import ceil\n",
    "import math\n",
    "import gaia_utils as gu\n",
    "from sklearn import cluster\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from astroML.correlation import two_point\n",
    "from astroML.correlation import bootstrap_two_point_angular\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## directory\n",
    "rootdir = \"/home/stephane/Science/GAIA\"\n",
    "wdir    = \"%s/products\"%(rootdir)\n",
    "datadir = \"%s/master/notebooks/data\"%(rootdir)\n",
    "\n",
    "os.chdir(wdir)\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "###################################\n",
    "\n",
    "clustername = \"NGC 1039\"\n",
    "# voname = 'NGC 752-1.0deg.vot'\n",
    "# voname = 'NGC 2682-3.0deg.vot'\n",
    "voname = 'NGC 1039-3.0deg.vot'\n",
    "RADIUS   = 3.0\n",
    "kCluster = 10\n",
    "votable_disk = False\n",
    "distclust = 510.0\n",
    "WEIGHT = [3.,3.,11.,4.,4., 3., 3., 3.]\n",
    "\n",
    "## dscan\n",
    "eps = 0.05\n",
    "min_samples = 30\n",
    "## Ward\n",
    "neighbors = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot2D and plot3D\n",
    "\n",
    "\n",
    "def plot2d(df, labels, ilab, cmap = \"gist_stern\" ,color = False):\n",
    "    \n",
    "    rcParams['figure.figsize'] = 14, 14\n",
    "    f, axarr = plt.subplots(2, 2)\n",
    "    \n",
    "    if color:\n",
    "        axarr[0,0].scatter(df[np.where(labels == ilab),0],df[np.where(labels == ilab),1],  s = 0.5, c= df[np.where(labels == ilab),2], cmap=cmap )\n",
    "    else:\n",
    "        axarr[0,0].scatter(df[np.where(labels == ilab),0],df[np.where(labels == ilab),1],  s = 0.5, c = \"k\")\n",
    "    axarr[0,0].set_xlabel(\"l\")\n",
    "    axarr[0,0].set_ylabel(\"b\")\n",
    "    \n",
    "    axarr[1,0].scatter(df[np.where(labels == ilab),0],df[np.where(labels == ilab),2] , s=0.5, c= df[np.where(labels == ilab),2], cmap=cmap)\n",
    "    axarr[1,0].set_xlabel(\"l\")\n",
    "    axarr[1,0].set_ylabel(\"d (pc)\")\n",
    "    \n",
    "    \n",
    "    axarr[0,1].scatter(df[np.where(labels == ilab),3],df[np.where(labels == ilab),4] , s= 0.5, c= df[np.where(labels == ilab),2], cmap=cmap)\n",
    "    axarr[0,1].set_xlabel(\"Vdra\")\n",
    "    axarr[0,1].set_ylabel(\"Vdec\")\n",
    "    \n",
    "    axarr[1,1].scatter(df[np.where(labels == ilab),6],df[np.where(labels == ilab),5] , s = 0.5, c= df[np.where(labels == ilab),2], cmap=cmap)\n",
    "    axarr[1,1].set_xlabel(\"G-R\")\n",
    "    axarr[1,1].set_ylabel(\"G\")\n",
    "    axarr[1,1].set_xlim(-1.,1.5)\n",
    "    axarr[1,1].set_ylim(27.,10)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## astrometric conversion\n",
    "## \n",
    "def convert_to_cartesian(lgal, bga, dist, offCenter = [0., 0.]):\n",
    "    \"Convert ra,dec (ICRS) and distance (pc) to Cartesian reference. Off is the offset in Lgal,Bgal\"\n",
    "    \n",
    "    xx = np.zeros(len(lgal))\n",
    "    yy = np.zeros(len(lgal))\n",
    "    zz = np.zeros(len(lgal))\n",
    "    \n",
    "    lgalOff = lgal - offCenter[0]\n",
    "    bgalOff = bgal - offCenter[1]\n",
    "    \n",
    "    print(offCenter[0])\n",
    "    print(offCenter[1])\n",
    "    print(min(lgalOff))\n",
    "    print(max(lgalOff))\n",
    "    print(min(bgalOff))\n",
    "    print(max(bgalOff))\n",
    "    \n",
    "    \n",
    "    for i in range(len(lgal)):\n",
    "        c = coord.SkyCoord(l=lgalOff[i]*u.degree, b=bgalOff[i]*u.degree, distance=dist[i]*u.pc, frame='galactic')\n",
    "        \n",
    "        xx[i] = c.cartesian.x.value\n",
    "        yy[i] = c.cartesian.y.value\n",
    "        zz[i] = c.cartesian.z.value\n",
    "        \n",
    "    print(\"## XX\")\n",
    "    print(\"min, max: %f , %f\"%(min(xx),max(xx)))\n",
    "    print(\"## YY\")\n",
    "    print(\"min, max: %f , %f\"%(min(yy),max(yy)))\n",
    "    print(\"## ZZ\")\n",
    "    print(\"min, max: %f , %f\"%(min(zz),max(zz)))  \n",
    "        \n",
    "    return(xx,yy,zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## NGC 1039-3.0deg.vot read...\n",
      "## Total stars: 59908\n",
      "## Conversion done...\n",
      "## Stars selected: 52114\n",
      "## Normalization minmax done on filtered data..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read the data and do the conversion\n",
    "\n",
    "\n",
    "source = gu.source(clustername)\n",
    "source.weight = WEIGHT\n",
    "#source.query(RADIUS, errtol = 0.2, dump = True)\n",
    "source.read_votable(voname)\n",
    "source.convert_filter_data(mag_range = [0., 40])\n",
    "#source.normalization_normal()\n",
    "source.normalization_minmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_corr(X, xrange = [0.1, RADIUS], nbins = 20):\n",
    "    \"Computing the 2-point correlation\"\n",
    "    \n",
    "    rlogmin = math.log10(xrange[0])\n",
    "    rlogmax = math.log10(xrange[1])\n",
    "    \n",
    "    bins = np.logspace(rlogmin, rlogmax, nbins)\n",
    "    print(bins)\n",
    "    corr = two_point(X, bins)\n",
    "\n",
    "    if not np.allclose(corr, 0, atol=0.02):\n",
    "        print(\"## Low correlation function\")\n",
    "    \n",
    "    bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "    \n",
    "    return(bin_center, corr)\n",
    "\n",
    "\n",
    "def angular_twoptcorr(x1, x2, xrange = [0.1, 1.], nbins = 20, Nbootstraps=10,  method='landy-szalay', rseed=0):\n",
    "    \"angular correlation using bootstraping\"\n",
    "    \n",
    "    np.random.seed(rseed)\n",
    "    rlogmin = math.log10(xrange[0])\n",
    "    rlogmax = math.log10(xrange[1])\n",
    "    \n",
    "    bins = np.logspace(rlogmin, rlogmax, nbins)\n",
    "    corr, corr_err, bootstraps = bootstrap_two_point_angular(x1, x2, bins=bins, method=method, Nbootstraps=Nbootstraps)\n",
    "\n",
    "    bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "    \n",
    "    return(bin_centers, corr, corr_err)\n",
    "    \n",
    "def plot_corr_label(X, labels, xrange, nbins = 20, errorbar = True):\n",
    "    \"plot the correlation function for i1,i2 of the data\"\n",
    "    \n",
    "    nclust = max(labels)\n",
    "    rcParams['figure.figsize'] = 14, 14\n",
    "    nrow = int(ceil(nclust / 3))\n",
    "    ncol = 3  \n",
    "\n",
    "    f, axarr = plt.subplots(ncol, nrow)\n",
    "\n",
    "    corrmax = []\n",
    "    corrlab = []\n",
    "    \n",
    "    for i in range(nclust):\n",
    "        ilabel = np.where(labels == i)[0]\n",
    "        row = int(i / 3)\n",
    "        col = i % 3   \n",
    "        \n",
    "        Xcenter = X[ilabel,:]\n",
    "        Xcenter[:,0] = Xcenter[:,0] - np.mean(Xcenter[:,0])\n",
    "        Xcenter[:,1] = Xcenter[:,1] - np.mean(Xcenter[:,1])\n",
    "        \n",
    "        xymax = max(max(Xcenter[:,0]), max(Xcenter[:,1]))\n",
    "        \n",
    "        if not errorbar:\n",
    "            bin_centers, corr = pt_corr(Xcenter, xrange = xrange, nbins = nbins)\n",
    "        else:\n",
    "            bin_centers, corr, corr_err = angular_twoptcorr(Xcenter[:,0], Xcenter[:,1] , xrange = xrange, nbins = nbins)\n",
    "        \n",
    "        if not errorbar:\n",
    "            axarr[row,col].semilogx(bins, corr, \"b-\")\n",
    "            axarr[row,col].set_xlabel(\"l(degree)\")\n",
    "            axarr[row,col].set_ylabel(\"corr\")\n",
    "        else:\n",
    "            axarr[row,col].errorbar(bin_centers, corr, corr_err,fmt='.k', ecolor='gray', lw=1)            \n",
    "            axarr[row,col].set_xlabel(r'$\\theta\\ (deg)$')\n",
    "            axarr[row,col].set_ylabel(r'$\\hat{w}(\\theta)$')\n",
    "            axarr[row,col].set_xscale(\"log\", nonposx='clip')\n",
    "            axarr[row,col].set_yscale(\"log\", nonposy='clip')\n",
    "\n",
    " \n",
    "        txt = \"Label: %d\"%(i)\n",
    "        axarr[row,col].text(0.1,1.02, txt, size=12, ha=\"left\", transform=axarr[row,col].transAxes)\n",
    "        \n",
    "        corrmax.append(max(corr))\n",
    "        corrlab.append(i)\n",
    "\n",
    "    arrcorr = list(zip(corrmax,corrlab))\n",
    "    arrcorr.sort(reverse=True)\n",
    "    plt.show()\n",
    "                       \n",
    "    return(arrcorr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## k-means...\n",
      "# Label     0 :  4322  Dist: 1471.2 (109.8)\n",
      "# Label     1 :  5797  Dist:  513.1 ( 99.7)\n",
      "# Label     2 :  5286  Dist:  846.9 (102.7)\n",
      "# Label     3 :  5560  Dist: 1814.6 ( 97.6)\n",
      "# Label     4 :  5953  Dist:  270.3 ( 85.2)\n",
      "# Label     5 :  5306  Dist:  824.3 (101.5)\n",
      "# Label     6 :  5387  Dist: 1146.8 (101.0)\n",
      "# Label     7 :  4288  Dist: 1482.5 (108.9)\n",
      "# Label     8 :  5549  Dist:  535.1 ( 99.2)\n",
      "# Label     9 :  4666  Dist: 1143.5 (109.5)\n",
      "##\n",
      "## Ward... \n"
     ]
    }
   ],
   "source": [
    "print(\"## k-means...\")\n",
    "\n",
    "# KMeans for each normalisation\n",
    "kmeans = cluster.KMeans(n_clusters= kCluster, max_iter = 2000, n_init = 50)\n",
    "kmeans.fit(source.dfnorm)\n",
    "labels_k = kmeans.labels_\n",
    "for i in range(kCluster):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_k[np.where(labels_k == i)]), np.median(source.df[np.where(labels_k == i),2]), np.std(source.df[np.where(labels_k == i),2])))\n",
    "print(\"##\")\n",
    "\n",
    "###########\n",
    "print(\"## Ward... \")\n",
    "# connectivity matrix for structured Ward\n",
    "\n",
    "connectivity = kneighbors_graph(source.dfnorm, n_neighbors= neighbors, include_self=False)\n",
    "# make connectivity symmetric\n",
    "connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "ward = cluster.AgglomerativeClustering(n_clusters= kCluster, linkage='ward', connectivity=connectivity)\n",
    "ward.fit(source.dfnorm)\n",
    "labels_w = ward.labels_\n",
    "for i in range(kCluster):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_w[np.where(labels_w == i)]), np.median(source.df[np.where(labels_w == i),2]),np.std(source.df[np.where(labels_w == i),2])))\n",
    "print(\"##\")\n",
    "    \n",
    "############# \n",
    "print(\"## Spectral...\")\n",
    "spectral = cluster.SpectralClustering(n_clusters = kCluster, eigen_solver='arpack', affinity=\"nearest_neighbors\")\n",
    "spectral.fit(source.dfnorm)\n",
    "labels_s = spectral.labels_\n",
    "for i in range(kCluster):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_s[np.where(labels_s == i)]), np.median(source.df[np.where(labels_s == i),2]),np.std(source.df[np.where(labels_s == i),2])))\n",
    "print(\"##\")\n",
    "\n",
    "\n",
    "############# \n",
    "print(\"## DBSCAN...\")\n",
    "dbscan = cluster.DBSCAN(eps, min_samples)\n",
    "dbscan.fit(source.dfnorm)\n",
    "labels_d = spectral.labels_\n",
    "for i in range(max(labels_d)):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_d[np.where(labels_d == i)]), np.median(source.df[np.where(labels_d == i),2]), np.std(source.df[np.where(labels_d == i),2]) ))\n",
    "print(\"##\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 2 pt-correlation\n",
    "icorr = [0,1]\n",
    "labs = labels_d\n",
    "corrlab = plot_corr_label(source.df[:,icorr], labs , xrange = [0.1,RADIUS], nbins = 20, errorbar = True)\n",
    "\n",
    "print(\"## 2 pt-correlation:\")\n",
    "for correlation in corrlab:\n",
    "    print(\"## Label %d, Corr: %4.3f, Dist: %3.1f\"%(correlation[1], correlation[0],np.median(source.df[np.where(labs == correlation[1]),2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2d(source.df, labels_s,4, cmap = \"nipy_spectral\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
