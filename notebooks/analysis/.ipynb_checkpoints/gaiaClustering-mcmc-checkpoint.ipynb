{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests\n",
    "Use of the agglomerative clustering with HR diagram.\n",
    "\n",
    "We try to optimize the weighting parameters with a clustering method using a MCMC approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from math import ceil\n",
    "import math\n",
    "import gaia_utils as gu\n",
    "from sklearn import cluster\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## directory\n",
    "rootdir = \"/home/stephane/Science/GAIA\"\n",
    "wdir    = \"%s/products\"%(rootdir)\n",
    "datadir = \"%s/master/notebooks/data\"%(rootdir)\n",
    "\n",
    "os.chdir(wdir)\n",
    "rcParams['figure.figsize'] = 9, 6\n",
    "###################################\n",
    "\n",
    "clustername = \"NGC 1647\"\n",
    "# voname = 'NGC 752-1.0deg.vot'\n",
    "# voname = 'NGC 2682-3.0deg.vot'\n",
    "voname = 'NGC 1647-2.0deg.vot'\n",
    "RADIUS   = 2.0\n",
    "kCluster = 7\n",
    "votable_disk = False\n",
    "distclust = 572.0\n",
    "WEIGHT = [3.,3.,11.,5.,5., 2., 2., 2.]\n",
    "WEIGHT = [4.87863010104081, 4.87863010104081, 4.306272782136562, 2.5786331381796077, 2.5786331381796077, 1.4117964989460319, 1.4117964989460319, 1.4117964989460319]\n",
    "\n",
    "## dscan\n",
    "eps = 0.05\n",
    "min_samples = 30\n",
    "## Ward\n",
    "neighbors = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Read the data and do the conversion\n",
    "\n",
    "\n",
    "source = gu.source(clustername)\n",
    "source.weight = WEIGHT\n",
    "#source.query(RADIUS, errtol = 0.2, dump = True)\n",
    "source.read_votable(voname)\n",
    "source.convert_filter_data(mag_range = [0., 40])\n",
    "source.normalization_normal()\n",
    "#source.normalization_minmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "Metric to quantify goodness-of-solution for the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric1(df, labels, APERTURE = 0.2 , MAXRADIUS = 1. , NBOOTSTRAP =20 ):\n",
    "    \"Using the density contrat assuming the OC is at the center\"\n",
    "    \n",
    "    xc   = np.mean(df[:,0])\n",
    "    yc   = np.mean(df[:,1]) \n",
    "    \n",
    "    nlab = max(labels)+1\n",
    "    aper2 = APERTURE*APERTURE\n",
    "    metric = {}\n",
    "    metric['label'] = []\n",
    "    metric['Q'] = []\n",
    "    metric['Q_err'] = []\n",
    "    \n",
    "    for ilab in range(nlab):\n",
    "        \n",
    "        dflab = df[np.where(labels == ilab),:][0]\n",
    "        radii = (dflab[:,0]- xc)*(dflab[:,0]- xc)+(dflab[:,1]- yc)*(dflab[:,1]- yc)\n",
    "        nclust = radii[np.where(radii < aper2)]\n",
    "        dens_clust = len(nclust) / aper2\n",
    "        \n",
    "        angle_out = np.random.uniform(0., 2*math.pi, NBOOTSTRAP)\n",
    "        rad_out   = np.random.uniform(APERTURE,MAXRADIUS-APERTURE, NBOOTSTRAP)\n",
    "        \n",
    "        Q_c = np.zeros(NBOOTSTRAP)\n",
    "        \n",
    "        for k in range(NBOOTSTRAP): \n",
    "            xi = xc + rad_out[k]*math.cos(angle_out[k])\n",
    "            yi = yc + rad_out[k]*math.sin(angle_out[k])\n",
    "            radii_out = (dflab[:,0]- xi)*(dflab[:,0]- xi)+(dflab[:,1]- yi)*(dflab[:,1]- yi)\n",
    "            nout = radii_out[np.where(radii_out < aper2)]\n",
    "            dens_out_k = max(1,len(nout)) / aper2\n",
    "            Q_c[k] = dens_clust / dens_out_k\n",
    "            \n",
    "        metric['label'].append(ilab)\n",
    "        metric['Q'].append(np.mean(Q_c))\n",
    "        metric['Q_err'].append(np.std(Q_c))\n",
    "        \n",
    "    return(metric)\n",
    "                          \n",
    "@jit\n",
    "def metric2(df, labels, APERTURE = 0.2 , MAXRADIUS = 1. , NBOOTSTRAP = 50 , SIGCLIP = 0.):\n",
    "    \"Using the density contrat assuming the OC is at the center and the distribution around is regular (no holes)\"\n",
    "        \n",
    "    epsilon = 0.1\n",
    "    xc   = np.mean(df[:,0])\n",
    "    yc   = np.mean(df[:,1]) \n",
    "    \n",
    "    nlab = max(labels)+1\n",
    "    aper2 = APERTURE*APERTURE\n",
    "    metric = {}\n",
    "    metric['label'] = []\n",
    "    metric['Q'] = []\n",
    "    metric['Q_err'] = []\n",
    "    \n",
    "    for ilab in range(nlab):\n",
    "        \n",
    "        dflab = df[np.where(labels == ilab),:][0]\n",
    "        radii = (dflab[:,0]- xc)*(dflab[:,0]- xc)+(dflab[:,1]- yc)*(dflab[:,1]- yc)\n",
    "        nclust = radii[np.where(radii < aper2)]\n",
    "        dens_clust = len(nclust) / aper2\n",
    "        \n",
    "        angle_out = np.random.uniform(0., 2*math.pi, NBOOTSTRAP)\n",
    "        rad_out   = np.random.uniform(APERTURE,MAXRADIUS-APERTURE, NBOOTSTRAP)\n",
    "        \n",
    "        nstarsout = np.zeros(NBOOTSTRAP)\n",
    "        \n",
    "        for k in range(NBOOTSTRAP): \n",
    "            xi = xc + rad_out[k]*math.cos(angle_out[k])\n",
    "            yi = yc + rad_out[k]*math.sin(angle_out[k])\n",
    "            radii_out = (dflab[:,0]- xi)*(dflab[:,0]- xi)+(dflab[:,1]- yi)*(dflab[:,1]- yi)\n",
    "            nout = radii_out[np.where(radii_out < aper2)]\n",
    "            nstarsout[k] = len(nout) + np.random.uniform(1., 1.+ epsilon)\n",
    "                \n",
    "        outmean = np.mean(nstarsout)\n",
    "        outstd  = np.std(nstarsout)\n",
    "        \n",
    "        nstar_filtered = np.where( (nstarsout - outmean)/ outstd > SIGCLIP )\n",
    "\n",
    "        dens_out = nstarsout[nstar_filtered] / aper2\n",
    "        Q_c = np.zeros(len(dens_out))\n",
    "        Q_c = dens_clust / dens_out\n",
    "        \n",
    "        metric['label'].append(ilab)\n",
    "        metric['Q'].append(np.mean(Q_c))\n",
    "        metric['Q_err'].append(np.std(Q_c))\n",
    "        \n",
    "    return(metric)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def updateWeight(weight,scale):\n",
    "    \"update the weight with a normal distribution\"\n",
    "    \n",
    "    weight_u = weight\n",
    "    norw  = np.random.normal(scale = scale, size = 4)\n",
    "    weight_u[0] += norw[0]            ## l\n",
    "    weight_u[1] += norw[0]            ## b\n",
    "    weight_u[2] += norw[1]            ## distance\n",
    "    weight_u[3] += norw[2]            ## vel\n",
    "    weight_u[4] += norw[2]            ## vel  \n",
    "    weight_u[5] += norw[3]            ## mag,color     \n",
    "    weight_u[6] += norw[3]            ## mag,color \n",
    "    weight_u[7] += norw[3]            ## mag,color \n",
    "    \n",
    "    if weight_u[0] < 1. :\n",
    "        weight_u[0] -= 2* norw[0]\n",
    "        weight_u[1] -= 2* norw[0]\n",
    "        \n",
    "    if weight_u[2] < 1. :\n",
    "        weight_u[0] -= 2* norw[1]\n",
    "        \n",
    "    if weight_u[3] < 1. :\n",
    "        weight_u[3] -= 2* norw[2]\n",
    "        weight_u[4] -= 2* norw[2]\n",
    "        \n",
    "    if weight_u[5] < 1. :\n",
    "        weight_u[5] -= 2* norw[3]\n",
    "        weight_u[6] -= 2* norw[3]    \n",
    "        weight_u[7] -= 2* norw[3] \n",
    "        \n",
    "    return(weight_u)\n",
    "    \n",
    "\n",
    "def mcmc_weighting( weight_0, kclust , von = \"test.vot\",  radius = 1, ITERMAX = 100, SCAN = None, SCALE = 1.):\n",
    "    \"Sample with NBOOTSTRAP trial in the weight range to get the Q\"\n",
    "    \n",
    "    np.random.seed()\n",
    "    \n",
    "    s = gu.source(clustername)\n",
    "    s.read_votable(von)\n",
    "    s.convert_filter_data(mag_range = [0., 40])\n",
    "    \n",
    "    aper = 0.5\n",
    "    \n",
    "    if SCAN == None:\n",
    "        metric = {}\n",
    "        metric['kmeans'] = {}\n",
    "        metric['kmeans']['weight'] = []\n",
    "        metric['kmeans']['metric'] = []\n",
    "        metric['ward'] = {}\n",
    "        metric['ward']['weight'] = []\n",
    "        metric['ward']['metric'] = []\n",
    "        metric['spectral'] = {}\n",
    "        metric['spectral']['weight'] = []\n",
    "        metric['spectral']['metric'] = []\n",
    "        metric['dbscan'] = {}\n",
    "        metric['dbscan']['weight'] = []\n",
    "        metric['dbscan']['metric'] = []\n",
    "    else:\n",
    "        metric = SCAN\n",
    "        \n",
    "     \n",
    "    WEIGHT = weight_0\n",
    "    index = 0\n",
    "    L_1 = 1e-7\n",
    "    Loop = True\n",
    "    \n",
    "    while Loop:\n",
    "        \n",
    "        nclust = kclust\n",
    "        \n",
    "        s.weight = updateWeight(WEIGHT, SCALE)\n",
    "        s.normalization_normal()\n",
    "        \n",
    "        # kmeans\n",
    "        kmeans = cluster.KMeans(n_clusters= nclust, max_iter = 2000, n_init = 50)\n",
    "        kmeans.fit(s.dfnorm)\n",
    "        labels_k = kmeans.labels_\n",
    "        qk = metric2(s.df, labels_k, APERTURE = aper , MAXRADIUS = 0.9 * radius , NBOOTSTRAP =50 )\n",
    "\n",
    "        print(\"# k-means done\")\n",
    "                            \n",
    "        # ward\n",
    "        connectivity = kneighbors_graph(source.dfnorm, n_neighbors= neighbors, include_self=False)\n",
    "        # make connectivity symmetric\n",
    "        connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "        ward = cluster.AgglomerativeClustering(n_clusters= nclust, linkage='ward', connectivity=connectivity)\n",
    "        ward.fit(s.dfnorm)\n",
    "        labels_w = ward.labels_\n",
    "        qw = metric2(s.df, labels_w, APERTURE = aper , MAXRADIUS = 0.9 * radius , NBOOTSTRAP =50 )\n",
    "\n",
    "        print(\"# Ward done\")\n",
    "        \n",
    "        # Spectral\n",
    "        # spectral = cluster.SpectralClustering(n_clusters = nclust, eigen_solver='arpack', affinity=\"nearest_neighbors\")\n",
    "        # spectral.fit(s.dfnorm)\n",
    "        # labels_s = spectral.labels_\n",
    "        # qs = metric2(s.df, labels_s, APERTURE = aper , MAXRADIUS = 0.9 * radius , NBOOTSTRAP =50 )\n",
    "\n",
    "        # print(\"# Spectral done\")\n",
    "        \n",
    "        # DBSCAN\n",
    "        eps = 0.05\n",
    "        min_samples = 30\n",
    "        dbscan = cluster.DBSCAN(eps, min_samples)\n",
    "        dbscan.fit(s.dfnorm)\n",
    "        labels_d = dbscan.labels_\n",
    "        qd = metric2(s.df, labels_d, APERTURE = aper , MAXRADIUS = 0.9 * radius , NBOOTSTRAP =50 )\n",
    "\n",
    "        print(\"# DBSCAN done\")\n",
    "        \n",
    "        #######\n",
    "        ## Test update on ...\n",
    "        Q = max(qw[\"Q\"])\n",
    "        L_2 = 1.- 1./Q\n",
    "        R   = L_2 / L_1\n",
    "        \n",
    "        r   = np.random.uniform(0.,1.)\n",
    "        index += 1\n",
    "        \n",
    "        if R > r:\n",
    "            WEIGHT = s.weight\n",
    "            L_1 = L_2\n",
    "            print(\"## Index : %d\"%(index))\n",
    "            print(\"## Q: %3.1f\"%(Q))\n",
    "            \n",
    "        if index > ITERMAX :\n",
    "            Loop = False\n",
    "            \n",
    "\n",
    "    print(\"## Weight:\")\n",
    "    print(WEIGHT)\n",
    "    print(\"## Done...\")\n",
    "    \n",
    "    metric['kmeans']['weight'] = WEIGHT\n",
    "    metric['kmeans']['metric'] = qk\n",
    "    metric['ward']['weight'] = WEIGHT\n",
    "    metric['ward']['metric'] = qw\n",
    "    # metric['spectral']['weight'] = WEIGHT\n",
    "    # metric['spectral']['metric'] = qs\n",
    "    metric['dbscan']['weight'] = WEIGHT\n",
    "    metric['dbscan']['metric'] = qd\n",
    "        \n",
    "    return(metric)       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## testing loop on parameters ..\n",
    "## Could be very long!!!\n",
    "## To continue a previous scan..\n",
    "#with open('dataQmcmc.pickle', 'rb') as f:\n",
    "#    previousMetric = pickle.load(f)\n",
    "\n",
    "w_0 = [2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0]\n",
    "q = mcmc_weighting( w_0, kCluster , von = voname,  radius = 2., ITERMAX = 1000, SCAN = None, SCALE = 0.05)\n",
    "\n",
    "with open('dataQmcmc.pickle', 'wb') as f:\n",
    "    pickle.dump(q, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
