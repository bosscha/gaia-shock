{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis GAIA M67 DR2\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u  # Simplify unity manipulation\n",
    "from astropy.coordinates import SkyCoord # To handle sky/space coordinates\n",
    "from astroquery.gaia import Gaia\n",
    "from astropy.io.votable import parse\n",
    "\n",
    "from pylab import rcParams\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## directory\n",
    "rootdir = \"/home/stephane/Science/GAIA\"\n",
    "wdir    = \"%s/products\"%(rootdir)\n",
    "datadir = \"%s/master/notebooks/data\"%(rootdir)\n",
    "\n",
    "os.chdir(wdir)\n",
    "\n",
    "#### parameters\n",
    "voname = \"n2682.vot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading votable & data manipulation fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the votable\n",
    "def reading_votable(path_voname) :\n",
    "    votable = parse(path_voname)\n",
    "    for table in votable.iter_tables():\n",
    "        data = table.array\n",
    "        #print(data.dtype.names)\n",
    "    return data\n",
    "\n",
    "## Convert data to array\n",
    "def convert_data(data) :\n",
    "    # Getting variables\n",
    "    lgal = data['l']\n",
    "    bgal = data['b']\n",
    "    pmas = data['parallax']\n",
    "    distance = 1000. / np.ma.filled(pmas, -9999999.) #distance = 1000/parallax\n",
    "    pmra = np.ma.filled(data['pmra'], -9999999.) # right assention\n",
    "    pmdec= np.ma.filled(data['pmdec'],-9999999.) #proper motion declinente\n",
    "    vdec = 4.74 * pmdec / pmas   ##? (pour )\n",
    "    vra  = 4.74 * pmra  / pmas   # pour avoir des km.s-1\n",
    "    \n",
    "    #para_abs_error = data['parallax_error']/data['parallax']\n",
    "    g = data['phot_g_mean_mag']; bp = data['phot_bp_mean_mag']; rp = data['phot_rp_mean_mag']\n",
    "    \n",
    "    #filtering\n",
    "    dist_range = [0., 2000]; vra_range = [-200,200]; vdec_range = [-200.,200]\n",
    "    \n",
    "    i1 = np.where((distance >= dist_range[0]) & (distance < dist_range[1]))\n",
    "    i2 = np.where((vra >= vra_range[0]) & (vra < vra_range[1]))\n",
    "    i12 = np.intersect1d(i1,i2)\n",
    "    i3 = np.where((vdec >= vdec_range[0]) & (vdec < vdec_range[1]))\n",
    "    ifinal = np.intersect1d(i12,i3)\n",
    "    \n",
    "    return np.array([lgal[ifinal], bgal[ifinal], distance[ifinal], vra[ifinal], vdec[ifinal],\n",
    "                     g[ifinal], bp[ifinal], rp[ifinal]]).T\n",
    "\n",
    "#conversion of lgal, bgal, distance into cartesian coordinate\n",
    "def convert_to_cartesian(lgal, bgal, dist, centering = True):\n",
    "    #centering True = x coordinate point to cluster center\n",
    "    \"Convert ra,dec (ICRS) and distance (pc) to Cartesian reference. Off is the offset in Lgal,Bgal\"\n",
    "    \n",
    "    xx = np.zeros(len(lgal));  yy = np.zeros(len(lgal));  zz = np.zeros(len(lgal))\n",
    "    \n",
    "    lgalOff = lgal - np.mean(lgal)\n",
    "    bgalOff = bgal - np.mean(bgal)\n",
    "    \n",
    "    \n",
    "    for i in range(len(lgal)):\n",
    "        c = SkyCoord(l=lgalOff[i]*u.degree, b=bgalOff[i]*u.degree, distance=dist[i]*u.pc, frame='galactic')\n",
    "        \n",
    "        xx[i] = c.cartesian.x.value\n",
    "        yy[i] = c.cartesian.y.value\n",
    "        zz[i] = c.cartesian.z.value\n",
    "        \n",
    "    return np.array([xx,yy,zz]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data\n",
    "#### - data = [$lgal$, $bgal$, $distance$, $vra$, $vdec$, $g$, $b_p$, $r_p$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the votable\n",
    "raw_data = reading_votable(voname)\n",
    "print(voname+\"\\n## Total stars: %d\"%(len(raw_data)))\n",
    "\n",
    "# Select variables and Clean wrong values, return 2d array\n",
    "data = convert_data(raw_data)\n",
    "print(\"## Stars selected: %d\"%(len(data[:,0])))\n",
    "\n",
    "#cartesian coordinate data\n",
    "data_cartesian = np.zeros(data.shape)\n",
    "data_cartesian[:,:3] = convert_to_cartesian(data[:,0],data[:,1],data[:,2],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = reading_votable(voname)\n",
    "print(voname+\"\\n## Total stars: %d\"%(len(raw_data)))\n",
    "data3 = convert_data(raw_data)\n",
    "print(\"## Stars selected: %d\"%(len(data3[:,0])))\n",
    "data3_cartesian = np.zeros(data3.shape)\n",
    "data3_cartesian[:,:3] = convert_to_cartesian(data3[:,0],data3[:,1],data3[:,2],True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the 5d datask and also return the normalization vector\n",
    "# choix_norm = 0 (norme 0) et = 1 (norm 2)\n",
    "def normalization(data,choix_norm=1):\n",
    "    result = np.zeros(data.shape)\n",
    "    normalization_vector = np.zeros(5)\n",
    "    \n",
    "    for i in range(5) :\n",
    "        if choix_norm == 0 : normalization_vector[i] = np.max(abs(data[:,i]))\n",
    "        else               : normalization_vector[i] = np.linalg.norm(data[:,i])\n",
    "        result[:,i] = data[:,i]/normalization_vector[i]\n",
    "    \n",
    "    return(result,normalization_vector)\n",
    "\n",
    "\n",
    "#Normalized the 5d datask with linear projection from [min,max] to [0,1]\n",
    "def normalization0_1(data, weight = np.array([1,1,1,1,1])):\n",
    "    result = np.zeros(data.shape)\n",
    "    normalization_vector = np.zeros((5,2)) #Represente max and min    \n",
    "    \n",
    "    for i in range(5) :\n",
    "        normalization_vector[i,0] = np.max(data[:,i]) # max\n",
    "        normalization_vector[i,1] = np.min(data[:,i]) # min\n",
    "        result[:,i] = weight[i]*(data[:,i]-normalization_vector[i,1])/(normalization_vector[i,0]-normalization_vector[i,1])  \n",
    "        \n",
    "    return(result,normalization_vector)\n",
    "\n",
    "#Unnormalized Data with linear projection from [0,1] to [min,max]\n",
    "def unnormalization0_1(data, normalization_vector, weight = np.array([1,1,1,1,1])):\n",
    "    result = np.zeros(data.shape) \n",
    "    for i in range(5) :\n",
    "        result[:,i] = data[:,i]*(normalization_vector[i,0]-normalization_vector[i,1])/weight[i] + normalization_vector[i,1]\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight vector to allocate to each component\n",
    "weight = [1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"## Total stars: %d\"%(len(lgal)))\n",
    "\n",
    "# Clean wrong values, return (n,5) array\n",
    "datask = filter_data(lgal,bgal,distance,vra,vdec, cartesian = True)\n",
    "print(\"## Stars selected: %d\"%(len(datask[:,0])))\n",
    "\n",
    "#datanor0, normalization_vector0 = normalization(datask,0)\n",
    "#datanor1, normalization_vector1 = normalization(datask,1)\n",
    "#datanor2, normalization_vector2 = normalization0_1(datask, weight)\n",
    "\n",
    "# Normalization\n",
    "# datask  =  non-normalized\n",
    "# datanor0 = normalized norm0 (divided by max(abs(data)))\n",
    "# datanor1 = normalized norm2 (divided by np.linalg.norm(data[:,i]))\n",
    "# datanor2 = linear projection from [min,max] to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_error = data['parallax_error']*1000./(data['parallax']**2)\n",
    "dist_abs_error = distance_error/distance\n",
    "para_abs_error = data['parallax_error']/data['parallax']\n",
    "datask2 = filter_data2(lgal,bgal,distance,vra,vdec,para_abs_error, cartesian = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful tab\n",
    "colors = ['b','r','g','c','m','y','k','turquoise','orangered','darkgreen','sienna','navy','orangered','darkred','green','springgreen','turquoise','violet']\n",
    "string = ['non-normalized','normalized norm 0', 'normalized norm 2','normalized linearly between 0 and 1']\n",
    "data_name = ['lgal','bgal','distance','vdec','vra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(data3_cartesian[:,0], data3_cartesian[:,1], data3_cartesian[:,2], zdir='z', s=0.01, c='k', depthshade=True)\n",
    "ax.set_xlabel('distance ($x$)', fontsize=35); ax.set_ylabel('$y$', fontsize=25); ax.set_zlabel('$z$', fontsize=25)\n",
    "ax.set_title('NGC2516', fontsize=30)\n",
    "#ax.view_init(30, 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.subplot(121)\n",
    "plt.title('M67 $unfiltered$', fontsize=18)\n",
    "plt.scatter(data_cartesian[:,1],data_cartesian[:,0],s=1,c='k')\n",
    "plt.ylabel('distance ($x$)', fontsize=18)\n",
    "plt.xlabel('$y$', fontsize=18); plt.subplot(122); plt.xlabel('$y$', fontsize=18)\n",
    "plt.title('M67 $filtered$', fontsize=18)\n",
    "plt.scatter(data2_cartesian[:,1],data2_cartesian[:,0],s=1,c='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data3_cartesian[:,0],data3_cartesian[:,5],s=1,c='k')\n",
    "plt.plot(data3_cartesian[:,0],0.1*np.ones(len(data3_cartesian[:,0])))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the HD diagram\n",
    "def HRD(data, data_name, size=0.1, colorbar = True) :\n",
    "    parallax = 1000./data[:,2]\n",
    "    \n",
    "    G_bar = data[:,5] + 5*np.log10(parallax) + 2\n",
    "    G_max = np.max(G_bar)\n",
    "    G_min = np.min(G_bar)\n",
    "    \n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.subplot(121)\n",
    "    plt.title(data_name, fontsize=20)\n",
    "    if colorbar : \n",
    "        plt.scatter(data[:,6]-data[:,5], G_bar, s=size, c=data[:,2], cmap='gist_stern')\n",
    "        clb = plt.colorbar()\n",
    "        clb.set_label('distance', labelpad=-40, y=1.05, rotation=0)\n",
    "    else : plt.scatter(data[:,6]-data[:,5], G_bar, s=1, c='k')\n",
    "    plt.ylim(G_max, G_min)\n",
    "    plt.xlabel('$B_p - G$', fontsize=18)\n",
    "    plt.ylabel(r'$G + 5 * log_{10}\\bar{\\omega} + 2$', fontsize=22)\n",
    "    plt.subplot(122)\n",
    "    plt.title(data_name, fontsize=20)\n",
    "    if colorbar : \n",
    "        plt.scatter(data[:,5]-data[:,7], G_bar, s=size, c=data[:,2], cmap='gist_stern')\n",
    "        clb = plt.colorbar()\n",
    "        clb.set_label('distance', labelpad=-40, y=1.05, rotation=0)\n",
    "    else : plt.scatter(data[:,5]-data[:,6], G_bar, s=1, c='k')\n",
    "    plt.ylim(G_max, G_min)\n",
    "    plt.xlabel('$G - R_p$', fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HRD(data3, \"NGC2516\", size=0.001, colorbar=True)\n",
    "i1 = np.where((data3[:,2] < 500))[0]\n",
    "HRD(data3[i1,:], \"NGC2516 500 dist cut\", size=0.01, colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------\n",
    "## Plotting before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,19))\n",
    "\n",
    "for i in (0,2,3,4) :\n",
    "    if i == 0 : j = 1\n",
    "    else      : j = i\n",
    "    plt.subplot(2,2,j)\n",
    "    plt.scatter(datask[:,1],datask[:,i],s=1,c='k')\n",
    "    plt.xlabel(data_name[1], fontsize=25)\n",
    "    plt.ylabel(data_name[i], fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitted cluster in k-means\n",
    "nclust = 12\n",
    "print(\"## computing k-means...\")\n",
    "\n",
    "# KMeans for each normalisation\n",
    "kmeans = KMeans(n_clusters=nclust, max_iter = 2000, n_init = 50)\n",
    "kmeans.fit(datask)\n",
    "kmeans_nor0 = KMeans(n_clusters=nclust, max_iter = 2000, n_init = 50)\n",
    "kmeans_nor0.fit(datanor0)\n",
    "kmeans_nor1 = KMeans(n_clusters=nclust, max_iter = 2000, n_init = 50)\n",
    "kmeans_nor1.fit(datanor1)\n",
    "kmeans_nor2 = KMeans(n_clusters=nclust, max_iter = 2000, n_init = 50)\n",
    "kmeans_nor2.fit(datanor2)\n",
    "\n",
    "# Centroid for each normalisation\n",
    "centroid = kmeans.cluster_centers_\n",
    "centroid_nor0 = np.multiply(kmeans_nor0.cluster_centers_, normalization_vector0)\n",
    "centroid_nor1 = np.multiply(kmeans_nor1.cluster_centers_, normalization_vector1)\n",
    "centroid_nor2 = unnormalization0_1(kmeans_nor2.cluster_centers_, normalization_vector2, weight)\n",
    "\n",
    "# Labels for each normalisation\n",
    "labels = kmeans.labels_\n",
    "labels_nor0 = kmeans_nor0.labels_\n",
    "labels_nor1 = kmeans_nor1.labels_\n",
    "labels_nor2 = kmeans_nor2.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting i2 with respect to i1\n",
    "# (0 = lgal; 1 = bgal; 2 = distance...)\n",
    "i1 = 1\n",
    "i2 = 2\n",
    "\n",
    "j = 1\n",
    "plt.figure(figsize=(25,22))\n",
    "centro = [centroid,centroid_nor0,centroid_nor1,centroid_nor2]\n",
    "for lab in (labels,labels_nor0,labels_nor1,labels_nor2) :\n",
    "    plt.subplot(2,2,j)\n",
    "    for i in range(nclust):\n",
    "        ilabel = np.where(lab == i)[0]\n",
    "        plt.scatter(datask[ilabel,i1],datask[ilabel,i2],s=1,c=colors[i])\n",
    "        plt.scatter(centro[j-1][i,i1],centro[j-1][i,i2],s=200,c=colors[i],marker='X')\n",
    "    plt.xlabel(data_name[i1], fontsize=22)\n",
    "    plt.ylabel(data_name[i2], fontsize=22)\n",
    "    plt.title(\"clustering with variables \" + string[j-1], fontsize=22)\n",
    "    j+=1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster plotting for data normalized linearly between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting i2 with respect to i1\n",
    "# (0 = lgal; 1 = bgal; 2 = distance...)\n",
    "i1 = 1\n",
    "i2 = 2\n",
    "\n",
    "plt.figure(figsize=(25,((nclust-1)//3+1)*6))\n",
    "for i in range(nclust):\n",
    "    plt.subplot((nclust-1)//3+1,3,i+1)\n",
    "    ilabel = np.where(labels_nor2 == i)[0]\n",
    "    plt.scatter(datask[ilabel,i1],datask[ilabel,i2],s=1,c=colors[i])\n",
    "    plt.scatter(centroid_nor2[i,i1],centroid_nor2[i,i2],s=200,c=colors[i],marker='X')\n",
    "    #plt.xlabel(data_name[i1], fontsize=22)\n",
    "    plt.ylabel(data_name[i2], fontsize=22)\n",
    "    plt.title(\"num. \" + str(i) + \" \" + data_name[i2] + \"=\" + str(round(centroid_nor2[i,i2],2)), fontsize=22)\n",
    "    plt.xlim(np.min(datask[:,i1]), np.max(datask[:,i1]))\n",
    "    plt.ylim(np.min(datask[:,i2]), np.max(datask[:,i2]))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in (1,2,3,4,5,8,10) :\n",
    "d = 2\n",
    "weight = [1, 1, d, 1, 1]\n",
    "data01, normalization_vector01 = normalization0_1(datask, weight)\n",
    "\n",
    "plt.figure(figsize=(25,23))\n",
    "i1 = 1\n",
    "i2 = 2\n",
    "\n",
    "for n in range(2,14) :\n",
    "\n",
    "    kmeans_01 = KMeans(n_clusters=n, max_iter = 2000, n_init = 50)\n",
    "    kmeans_01.fit(data01)\n",
    "\n",
    "    centroid_01 = unnormalization0_1(kmeans_01.cluster_centers_, normalization_vector01, weight)\n",
    "    labels_01 = kmeans_01.labels_\n",
    "\n",
    "\n",
    "    plt.subplot(4,3,n-1)\n",
    "    for i in range(n):\n",
    "        ilabel = np.where(labels_01 == i)[0]\n",
    "        plt.scatter(datask[ilabel,i1],datask[ilabel,i2],s=1,c=colors[i])\n",
    "        plt.scatter(centroid_01[i,i1],centroid_01[i,i2],s=200,c=colors[i],marker='X')\n",
    "    plt.xlabel(data_name[i1], fontsize=22)\n",
    "    plt.ylabel(data_name[i2], fontsize=22)\n",
    "    plt.title(\"num. of cluster : \" + str(n), fontsize=22)\n",
    "#plt.savefig('kmeans_cluser_[1-1-%s-1-1].png'%(d))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------\n",
    "\n",
    "### Description in pandas variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {'lgal': datask[:,0], 'bgal': datask[:,1], 'distance': datask[:,2], 'vra': datask[:,3], 'vdec': datask[:,4]}\n",
    "datapd = pd.DataFrame(data=d1)\n",
    "d2 = {'lgal': datanor0[:,0], 'bgal': datanor0[:,1], 'distance': datanor0[:,2], 'vra': datanor0[:,3], 'vdec': datanor0[:,4]}\n",
    "datapd_nor0 = pd.DataFrame(data=d2)\n",
    "d3 = {'lgal': datanor1[:,0], 'bgal': datanor1[:,1], 'distance': datanor1[:,2], 'vra': datanor1[:,3], 'vdec': datanor1[:,4]}\n",
    "datapd_nor1 = pd.DataFrame(data=d3)\n",
    "d4 = {'lgal': datanor2[:,0], 'bgal': datanor2[:,1], 'distance': datanor2[:,2], 'vra': datanor2[:,3], 'vdec': datanor2[:,4]}\n",
    "datapd_nor2 = pd.DataFrame(data=d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description for one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogram\n",
    "plt.figure(figsize=(25,15))\n",
    "i = 1\n",
    "for string in ('lgal','bgal','distance','vra','vdec'):\n",
    "    plt.subplot(2,3,i)\n",
    "    datapd[string].hist()\n",
    "    plt.xlabel(string, fontsize=25)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "\n",
    "i = 1\n",
    "string = ['non-normalized','normalized norm 0', 'normalized norm 2','normalized linearly between 0 and 1']\n",
    "data_i = [datapd,datapd_nor1,datapd_nor1,datapd_nor2]\n",
    "for data_i in (datapd,datapd_nor0,datapd_nor1,datapd_nor2):\n",
    "    data_i.plot(kind = \"box\",figsize=(15, 7))\n",
    "    plt.title(\"Boxplot, variables \" + string[i-1], fontsize=18)\n",
    "    i+=1\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(datapd, 'ward', metric='euclidean') # choix de la distance\n",
    "Z0 = linkage(datapd_nor0, 'ward', metric='euclidean') # choix de la distance\n",
    "Z1 = linkage(datapd_nor1, 'ward', metric='euclidean') # choix de la distance\n",
    "Z2 = linkage(datapd_nor2, 'ward', metric='euclidean') # choix de la distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ['non-normalized','normalized norm 0', 'normalized norm 2','normalized linearly between 0 and 1']\n",
    "Z_ = [Z,Z0,Z1,Z2]\n",
    "t = np.zeros((16,4))\n",
    "plt.figure(figsize=(14,10))\n",
    "x=np.arange(16)+1\n",
    "for i in range(4) :\n",
    "    plt.subplot(2,2,i+1)\n",
    "    height = Z_[i][:,2]\n",
    "    height = sorted(height,reverse=True)\n",
    "    plt.scatter(x,height[0:16])  #height[0:16]/sum(height[0:16])*100\n",
    "    t[:,i] = height[0:16]\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Height')\n",
    "    plt.title(\"Choice of the number of classes for \"+string[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ['non-normalized','normalized norm 0', 'normalized norm 2','normalized linearly between 0 and 1']\n",
    "Z_ = [Z,Z0,Z1,Z2]\n",
    "data_ = [datapd, datapd_nor0, datapd_nor1, datapd_nor2]\n",
    "plt.figure(figsize=(20,16))\n",
    "x=np.arange(16)+1\n",
    "for i in range(4) :\n",
    "    plt.subplot(2,2,i+1)\n",
    "    dendrogram(Z_[i],leaf_font_size=8.,labels=data_[i].index)\n",
    "    plt.xlabel('Individus')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.title(string[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Individus')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(Z,leaf_font_size=8.,labels=marsRech.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesCAH = fcluster(Z,t=15,criterion='distance')\n",
    "pd.DataFrame(classesCAH).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classesCAH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"r.\",\"k.\",\"g.\",\"y.\",\"b.\",\"k.\",\"b.\",\"g.\",\"y.\",\"c.\",\"r.\",\"k.\",\"g.\",\"y.\",\"w.\",\"k.\",\"b.\",\"g.\",\"y.\",\"c.\",\"r.\",\"k.\",\"g.\",\"y.\",\"w.\",\"k.\",\"b.\",\"g.\",\"y.\",\"c.\"]\n",
    "rcParams['figure.figsize'] = 8, 8\n",
    "\n",
    "for i in range(4):\n",
    "    ilabel = np.where(classesCAH == i)[0]\n",
    "    plt.plot(datask[ilabel,1],datask[ilabel,2],colors[i],markersize=1)\n",
    "    #plt.scatter(centroid_nor[0,0],centroid_nor[0,1],'y',markersize=10)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"r.\",\"k.\",\"g.\",\"y.\",\"b.\",\"k.\",\"b.\",\"g.\",\"y.\",\"c.\",\"r.\",\"k.\",\"g.\",\"y.\",\"w.\",\"k.\",\"b.\",\"g.\",\"y.\",\"c.\",\"r.\",\"k.\",\"g.\",\"y.\",\"w.\",\"k.\",\"b.\",\"g.\",\"y.\",\"c.\"]\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "i1 = 1\n",
    "i2 = 2\n",
    "string = ['non-normalized','normalized norm 0', 'normalized norm 2','normalized linearly between 0 and 1']\n",
    "plt.figure(figsize=(25,22))\n",
    "centro = [centroid,centroid_nor0,centroid_nor1,centroid_nor2]\n",
    "\n",
    "\n",
    "for i in range(nclust):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    ilabel = np.where(labels_nor0 == i)[0]\n",
    "    plt.plot(datask[labels_nor0,i1],datask[labels_nor0,i2],colors[i],markersize=1)\n",
    "    plt.plot(centroid_nor0[i,i1],centroid_nor0[i,i2],colors[i],markersize=19)\n",
    "    plt.xlabel(\"bgal\", fontsize=22)\n",
    "    plt.ylabel(\"distance\", fontsize=22)\n",
    "    plt.title(\"cluste num. \" + str(j), fontsize=22)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
