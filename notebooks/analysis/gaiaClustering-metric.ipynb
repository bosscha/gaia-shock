{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests\n",
    "Use of the agglomerative clustering with HR diagram.\n",
    "\n",
    "We test here metrics to detect good solutions for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../../src')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from math import ceil\n",
    "import math\n",
    "import gaia_utils as gu\n",
    "from sklearn import cluster\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from astroML.correlation import two_point\n",
    "from astroML.correlation import bootstrap_two_point_angular\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## directory\n",
    "rootdir = \"/home/stephane/Science/GAIA\"\n",
    "wdir    = \"%s/products\"%(rootdir)\n",
    "datadir = \"%s/master/notebooks/data\"%(rootdir)\n",
    "\n",
    "os.chdir(wdir)\n",
    "rcParams['figure.figsize'] = 9, 6\n",
    "###################################\n",
    "\n",
    "clustername = \"NGC 1647\"\n",
    "# voname = 'NGC 752-1.0deg.vot'\n",
    "# voname = 'NGC 2682-3.0deg.vot'\n",
    "voname = 'NGC 1647-2.0deg.vot'\n",
    "RADIUS   = 2.0\n",
    "kCluster = 10\n",
    "votable_disk = False\n",
    "distclust = 810.0\n",
    "WEIGHT = [3.,3.,11.,5.,5., 2., 2., 2.]\n",
    "\n",
    "## dscan\n",
    "eps = 0.05\n",
    "min_samples = 30\n",
    "## Ward\n",
    "neighbors = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot2D and plot3D\n",
    "\n",
    "\n",
    "def plot2d(df, labels, ilab, cmap = \"gist_stern\" ,color = False):\n",
    "    \n",
    "    rcParams['figure.figsize'] = 14, 14\n",
    "    f, axarr = plt.subplots(2, 2)\n",
    "    \n",
    "    if color:\n",
    "        axarr[0,0].scatter(df[np.where(labels == ilab),0],df[np.where(labels == ilab),1],  s = 0.5, c= df[np.where(labels == ilab),2], cmap=cmap )\n",
    "    else:\n",
    "        axarr[0,0].scatter(df[np.where(labels == ilab),0],df[np.where(labels == ilab),1],  s = 0.5, c = \"k\")\n",
    "    axarr[0,0].set_xlabel(\"l\")\n",
    "    axarr[0,0].set_ylabel(\"b\")\n",
    "    \n",
    "    axarr[1,0].scatter(df[np.where(labels == ilab),0],df[np.where(labels == ilab),2] , s=0.5, c= df[np.where(labels == ilab),2], cmap=cmap)\n",
    "    axarr[1,0].set_xlabel(\"l\")\n",
    "    axarr[1,0].set_ylabel(\"d (pc)\")\n",
    "    \n",
    "    \n",
    "    axarr[0,1].scatter(df[np.where(labels == ilab),3],df[np.where(labels == ilab),4] , s= 0.5, c= df[np.where(labels == ilab),2], cmap=cmap)\n",
    "    axarr[0,1].set_xlabel(\"Vdra\")\n",
    "    axarr[0,1].set_ylabel(\"Vdec\")\n",
    "    \n",
    "    axarr[1,1].scatter(df[np.where(labels == ilab),6],df[np.where(labels == ilab),5] , s = 0.5, c= df[np.where(labels == ilab),2], cmap=cmap)\n",
    "    axarr[1,1].set_xlabel(\"G-R\")\n",
    "    axarr[1,1].set_ylabel(\"G\")\n",
    "    axarr[1,1].set_xlim(-1.,1.5)\n",
    "    axarr[1,1].set_ylim(27.,10)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## astrometric conversion\n",
    "## \n",
    "def convert_to_cartesian(lgal, bga, dist, offCenter = [0., 0.]):\n",
    "    \"Convert ra,dec (ICRS) and distance (pc) to Cartesian reference. Off is the offset in Lgal,Bgal\"\n",
    "    \n",
    "    xx = np.zeros(len(lgal))\n",
    "    yy = np.zeros(len(lgal))\n",
    "    zz = np.zeros(len(lgal))\n",
    "    \n",
    "    lgalOff = lgal - offCenter[0]\n",
    "    bgalOff = bgal - offCenter[1]\n",
    "    \n",
    "    print(offCenter[0])\n",
    "    print(offCenter[1])\n",
    "    print(min(lgalOff))\n",
    "    print(max(lgalOff))\n",
    "    print(min(bgalOff))\n",
    "    print(max(bgalOff))\n",
    "    \n",
    "    \n",
    "    for i in range(len(lgal)):\n",
    "        c = coord.SkyCoord(l=lgalOff[i]*u.degree, b=bgalOff[i]*u.degree, distance=dist[i]*u.pc, frame='galactic')\n",
    "        \n",
    "        xx[i] = c.cartesian.x.value\n",
    "        yy[i] = c.cartesian.y.value\n",
    "        zz[i] = c.cartesian.z.value\n",
    "        \n",
    "    print(\"## XX\")\n",
    "    print(\"min, max: %f , %f\"%(min(xx),max(xx)))\n",
    "    print(\"## YY\")\n",
    "    print(\"min, max: %f , %f\"%(min(yy),max(yy)))\n",
    "    print(\"## ZZ\")\n",
    "    print(\"min, max: %f , %f\"%(min(zz),max(zz)))  \n",
    "        \n",
    "    return(xx,yy,zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Read the data and do the conversion\n",
    "\n",
    "\n",
    "source = gu.source(clustername)\n",
    "source.weight = WEIGHT\n",
    "#source.query(RADIUS, errtol = 0.2, dump = True)\n",
    "source.read_votable(voname)\n",
    "source.convert_filter_data(mag_range = [0., 40])\n",
    "source.normalization_normal()\n",
    "#source.normalization_minmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "Metric to quantify goodness-of-solution for the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric1(df, labels, APERTURE = 0.2 , MAXRADIUS = 1. , NBOOTSTRAP =20 ):\n",
    "    \"Using the density contrat assuming the OC is at the center\"\n",
    "    \n",
    "    xc   = np.mean(df[:,0])\n",
    "    yc   = np.mean(df[:,1]) \n",
    "    \n",
    "    nlab = max(labels)+1\n",
    "    aper2 = APERTURE*APERTURE\n",
    "    metric = {}\n",
    "    metric['label'] = []\n",
    "    metric['Q'] = []\n",
    "    metric['Q_err'] = []\n",
    "    \n",
    "    for ilab in range(nlab):\n",
    "        \n",
    "        dflab = df[np.where(labels == ilab),:][0]\n",
    "        radii = (dflab[:,0]- xc)*(dflab[:,0]- xc)+(dflab[:,1]- yc)*(dflab[:,1]- yc)\n",
    "        nclust = radii[np.where(radii < aper2)]\n",
    "        dens_clust = len(nclust) / aper2\n",
    "        \n",
    "        angle_out = np.random.uniform(0., 2*math.pi, NBOOTSTRAP)\n",
    "        rad_out   = np.random.uniform(APERTURE,MAXRADIUS-APERTURE, NBOOTSTRAP)\n",
    "        \n",
    "        Q_c = np.zeros(NBOOTSTRAP)\n",
    "        \n",
    "        for k in range(NBOOTSTRAP): \n",
    "            xi = xc + rad_out[k]*math.cos(angle_out[k])\n",
    "            yi = yc + rad_out[k]*math.sin(angle_out[k])\n",
    "            radii_out = (dflab[:,0]- xi)*(dflab[:,0]- xi)+(dflab[:,1]- yi)*(dflab[:,1]- yi)\n",
    "            nout = radii_out[np.where(radii_out < aper2)]\n",
    "            dens_out_k = max(1,len(nout)) / aper2\n",
    "            Q_c[k] = dens_clust / dens_out_k\n",
    "            \n",
    "        metric['label'].append(ilab)\n",
    "        metric['Q'].append(np.mean(Q_c))\n",
    "        metric['Q_err'].append(np.std(Q_c))\n",
    "        \n",
    "    return(metric)\n",
    "                          \n",
    "    \n",
    "def iter_parameters(angmin,angmax,dmin,dmax,vmin,vmax,magmin,magmax, kmin, kmax ,ntrial, von = \"test.vot\", radius = 1):\n",
    "    \"Range of the weight for each group of parameters\"\n",
    "        \n",
    "    s = gu.source(clustername)\n",
    "    s.read_votable(von)\n",
    "\n",
    "    metric = {}\n",
    "    angle = np.linspace(angmin,angmax,ntrial)\n",
    "    distance = np.linspace(dmin,dmax,ntrial)\n",
    "    vel   = np.linspace(vmin, vmax,ntrial)\n",
    "    mag   = np.linspace(magmin, magmax,ntrial)\n",
    "    kclus = range(kmin,kmax)\n",
    "    \n",
    "    metric['kmeans'] = {}\n",
    "    metric['kmeans']['weight'] = []\n",
    "    metric['kmeans']['metric'] = []\n",
    "                            \n",
    "                            \n",
    "    for a in angle:\n",
    "        for v in vel:\n",
    "            for m in mag:\n",
    "                for d in distance:\n",
    "                    for k in kclus:\n",
    "                        WEIGHT = [a,a,d,v,v,m,m,m] \n",
    "                        s.weight = WEIGHT\n",
    "                        s.convert_filter_data(mag_range = [0., 40])\n",
    "                        s.normalization_normal()\n",
    "    \n",
    "                        print(WEIGHT)\n",
    "        \n",
    "                        kmeans = cluster.KMeans(n_clusters= kCluster, max_iter = 2000, n_init = 50)\n",
    "                        kmeans.fit(s.dfnorm)\n",
    "                        labels_k = kmeans.labels_\n",
    "                        qk = metric1(s.df, labels_k, APERTURE = 0.2 , MAXRADIUS = radius , NBOOTSTRAP =10 )\n",
    "                        metric['kmeans']['weight'].append(WEIGHT)\n",
    "                        metric['kmeans']['metric'].append(qk)\n",
    "                            \n",
    "        \n",
    "    return(metric)\n",
    "\n",
    "def random_weighting(angmin,angmax,dmin,dmax,vmin,vmax,magmin,magmax, kmin, kmax , von = \"test.vot\", radius = 1, NBOOTSTRAP = 100, rseed = 0):\n",
    "    \"Sample with NBOOTSTRAP trial in the weight range to get the Q\"\n",
    "    \n",
    "    np.random.seed(rseed)\n",
    "    \n",
    "    s = gu.source(clustername)\n",
    "    s.read_votable(von)\n",
    "    \n",
    "    metric = {}\n",
    "    metric['kmeans'] = {}\n",
    "    metric['kmeans']['weight'] = []\n",
    "    metric['kmeans']['metric'] = []\n",
    "    metric['ward'] = {}\n",
    "    metric['ward']['weight'] = []\n",
    "    metric['ward']['metric'] = []\n",
    "    metric['spectral'] = {}\n",
    "    metric['spectral']['weight'] = []\n",
    "    metric['spectral']['metric'] = []\n",
    "    metric['dbscan'] = {}\n",
    "    metric['dbscan']['weight'] = []\n",
    "    metric['dbscan']['metric'] = []\n",
    "    \n",
    "    angle     = np.random.uniform(angmin, angmax, NBOOTSTRAP)\n",
    "    distance  = np.random.uniform(dmin, dmax, NBOOTSTRAP)\n",
    "    velocity  = np.random.uniform(vmin, vmax, NBOOTSTRAP)\n",
    "    magnitude = np.random.uniform(magmin, magmax, NBOOTSTRAP)\n",
    "    ncluster  = np.random.randint(kmin, kmax, NBOOTSTRAP)\n",
    "    \n",
    "    aper = 0.3\n",
    "            \n",
    "    for i in range(NBOOTSTRAP):\n",
    "        WEIGHT = [angle[i],angle[i],distance[i],velocity[i],velocity[i], magnitude[i],magnitude[i], magnitude[i]]\n",
    "        nclust = ncluster[i]\n",
    "        \n",
    "        s.weight = WEIGHT\n",
    "        s.convert_filter_data(mag_range = [0., 40])\n",
    "        s.normalization_normal()\n",
    "    \n",
    "        print(WEIGHT)\n",
    "        print(i)\n",
    "        \n",
    "        # kmeans\n",
    "        kmeans = cluster.KMeans(n_clusters= nclust, max_iter = 2000, n_init = 50)\n",
    "        kmeans.fit(s.dfnorm)\n",
    "        labels_k = kmeans.labels_\n",
    "        qk = metric1(s.df, labels_k, APERTURE = aper , MAXRADIUS = radius , NBOOTSTRAP =10 )\n",
    "        metric['kmeans']['weight'].append(WEIGHT)\n",
    "        metric['kmeans']['metric'].append(qk)\n",
    "        print(\"# k-means done\")\n",
    "                            \n",
    "        # ward\n",
    "        connectivity = kneighbors_graph(source.dfnorm, n_neighbors= neighbors, include_self=False)\n",
    "        # make connectivity symmetric\n",
    "        connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "        ward = cluster.AgglomerativeClustering(n_clusters= nclust, linkage='ward', connectivity=connectivity)\n",
    "        ward.fit(s.dfnorm)\n",
    "        labels_w = ward.labels_\n",
    "        qw = metric1(s.df, labels_w, APERTURE = aper , MAXRADIUS = radius , NBOOTSTRAP =10 )\n",
    "        metric['ward']['weight'].append(WEIGHT)\n",
    "        metric['ward']['metric'].append(qw)\n",
    "        print(\"# Ward done\")\n",
    "        \n",
    "        # Spectral\n",
    "        spectral = cluster.SpectralClustering(n_clusters = nclust, eigen_solver='arpack', affinity=\"nearest_neighbors\")\n",
    "        spectral.fit(s.dfnorm)\n",
    "        labels_s = spectral.labels_\n",
    "        qs = metric1(s.df, labels_s, APERTURE = aper , MAXRADIUS = radius , NBOOTSTRAP =10 )\n",
    "        metric['spectral']['weight'].append(WEIGHT)\n",
    "        metric['spectral']['metric'].append(qs)\n",
    "        print(\"# Spectral done\")\n",
    "        \n",
    "        # DBSCAN\n",
    "        eps = 0.05\n",
    "        min_samples = 30\n",
    "        dbscan = cluster.DBSCAN(eps, min_samples)\n",
    "        dbscan.fit(s.dfnorm)\n",
    "        labels_d = spectral.labels_\n",
    "        qd = metric1(s.df, labels_d, APERTURE = aper , MAXRADIUS = radius , NBOOTSTRAP =10 )\n",
    "        metric['dbscan']['weight'].append(WEIGHT)\n",
    "        metric['dbscan']['metric'].append(qd)\n",
    "        print(\"# DBSCAN done\")\n",
    "            \n",
    "    return(metric)       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing loop on parameters ..\n",
    "## Could be very long!!!\n",
    "\n",
    "np.random.seed(0)\n",
    "# q = iter_parameters(2.,5.,7.,12.,2.,4.,1.,3., 7,8 ,2, von = voname, radius = 2.)\n",
    "q = random_weighting(1.,7.,3.,15.,1.,7.,1.,5., 5 ,12 , von = voname, radius = 2., NBOOTSTRAP = 200)\n",
    "\n",
    "with open('dataQran.pickle', 'wb') as f:\n",
    "    pickle.dump(q, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"## k-means...\")\n",
    "\n",
    "# KMeans for each normalisation\n",
    "kmeans = cluster.KMeans(n_clusters= kCluster, max_iter = 2000, n_init = 50)\n",
    "kmeans.fit(source.dfnorm)\n",
    "labels_k = kmeans.labels_\n",
    "for i in range(kCluster):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_k[np.where(labels_k == i)]), np.median(source.df[np.where(labels_k == i),2]), np.std(source.df[np.where(labels_k == i),2])))\n",
    "print(\"##\")\n",
    "\n",
    "###########\n",
    "print(\"## Ward... \")\n",
    "# connectivity matrix for structured Ward\n",
    "\n",
    "connectivity = kneighbors_graph(source.dfnorm, n_neighbors= neighbors, include_self=False)\n",
    "# make connectivity symmetric\n",
    "connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "ward = cluster.AgglomerativeClustering(n_clusters= kCluster, linkage='ward', connectivity=connectivity)\n",
    "ward.fit(source.dfnorm)\n",
    "labels_w = ward.labels_\n",
    "for i in range(kCluster):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_w[np.where(labels_w == i)]), np.median(source.df[np.where(labels_w == i),2]),np.std(source.df[np.where(labels_w == i),2])))\n",
    "print(\"##\")\n",
    "    \n",
    "############# \n",
    "print(\"## Spectral...\")\n",
    "spectral = cluster.SpectralClustering(n_clusters = kCluster, eigen_solver='arpack', affinity=\"nearest_neighbors\")\n",
    "spectral.fit(source.dfnorm)\n",
    "labels_s = spectral.labels_\n",
    "for i in range(kCluster):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_s[np.where(labels_s == i)]), np.median(source.df[np.where(labels_s == i),2]),np.std(source.df[np.where(labels_s == i),2])))\n",
    "print(\"##\")\n",
    "\n",
    "\n",
    "############# \n",
    "print(\"## DBSCAN...\")\n",
    "dbscan = cluster.DBSCAN(eps, min_samples)\n",
    "dbscan.fit(source.dfnorm)\n",
    "labels_d = spectral.labels_\n",
    "for i in range(max(labels_d)+1):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_d[np.where(labels_d == i)]), np.median(source.df[np.where(labels_d == i),2]), np.std(source.df[np.where(labels_d == i),2]) ))\n",
    "print(\"##\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Metrics of the solutions\n",
    "np.random.seed(0)\n",
    "labs = labels_k\n",
    "qk = metric1(source.df, labs , APERTURE = 0.2 , MAXRADIUS = 0.9 * RADIUS) \n",
    "labs = labels_w\n",
    "qw = metric1(source.df, labs , APERTURE = 0.2 , MAXRADIUS = 0.9 * RADIUS) \n",
    "labs = labels_s\n",
    "qs = metric1(source.df, labs , APERTURE = 0.2 , MAXRADIUS = 0.9 * RADIUS) \n",
    "labs = labels_d\n",
    "qd = metric1(source.df, labs , APERTURE = 0.2 , MAXRADIUS = 0.9 * RADIUS)  \n",
    "\n",
    "plt.yscale(\"log\", nonposy='clip')\n",
    "plt.xlim([0,kCluster+1])\n",
    "plt.errorbar(qk['label'],qk['Q'], qk['Q_err'], label='k-means',fmt='.k', ecolor='gray', lw=1, capsize=5)\n",
    "plt.errorbar(qw['label'],qw['Q'], qw['Q_err'], label='Ward', fmt='*r', ecolor='gray', lw=1, capsize=5)\n",
    "plt.errorbar(qs['label'],qs['Q'], qs['Q_err'], label='Spectral', fmt='Db', ecolor='gray', lw=1, capsize=5)\n",
    "plt.errorbar(qd['label'],qd['Q'], qd['Q_err'], label='DBSCAN', fmt='og', ecolor='gray', lw=1, capsize=5)\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.xlabel(\"Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2d(source.df, labels_d,5, cmap = \"hsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
