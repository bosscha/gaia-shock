{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests\n",
    "Use of the agglomerative clustering with HR diagram.\n",
    "\n",
    "We test here metrics to detect good solutions for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from math import ceil\n",
    "import math\n",
    "import gaia_utils as gu\n",
    "from sklearn import cluster\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from astroML.correlation import two_point\n",
    "from astroML.correlation import bootstrap_two_point_angular\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## directory\n",
    "rootdir = \"/home/stephane/Science/GAIA\"\n",
    "wdir    = \"%s/products\"%(rootdir)\n",
    "datadir = \"%s/master/notebooks/data\"%(rootdir)\n",
    "\n",
    "os.chdir(wdir)\n",
    "rcParams['figure.figsize'] = 9, 6\n",
    "###################################\n",
    "\n",
    "clustername = \"NGC 1647\"\n",
    "# voname = 'NGC 752-1.0deg.vot'\n",
    "# voname = 'NGC 2682-3.0deg.vot'\n",
    "voname = 'NGC 1647-2.0deg.vot'\n",
    "voname = \"Ruprecht 1-2.0deg.vot\"\n",
    "RADIUS   = 2.0\n",
    "kCluster = 8\n",
    "votable_disk = False\n",
    "distclust = 572.0\n",
    "WEIGHT = [3.,3.,11.,5.,5., 2., 2., 2.]\n",
    "WEIGHT = [4.87863010104081, 4.87863010104081, 4.306272782136562, 2.5786331381796077, 2.5786331381796077, 1.4117964989460319, 1.4117964989460319, 1.4117964989460319]\n",
    "\n",
    "## dscan\n",
    "eps = 2.0\n",
    "min_samples = 20\n",
    "## Ward\n",
    "neighbors = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot2D and plot3D\n",
    "\n",
    "\n",
    "def plot2d(df, labels, ilab, cmap = \"gist_stern\" ,color = False):\n",
    "    \n",
    "    rcParams['figure.figsize'] = 14, 14\n",
    "    f, axarr = plt.subplots(2, 2)\n",
    "    \n",
    "    if color:\n",
    "        axarr[0,0].scatter(df[np.where(labels == ilab),0],df[np.where(labels == ilab),1],  s = 0.5, c= df[np.where(labels == ilab),2], cmap=cmap )\n",
    "    else:\n",
    "        axarr[0,0].scatter(df[np.where(labels == ilab),0],df[np.where(labels == ilab),1],  s = 0.5, c = \"k\")\n",
    "    axarr[0,0].set_xlabel(\"l\")\n",
    "    axarr[0,0].set_ylabel(\"b\")\n",
    "    \n",
    "    axarr[1,0].scatter(df[np.where(labels == ilab),0],df[np.where(labels == ilab),2] , s=0.5, c= df[np.where(labels == ilab),2], cmap=cmap)\n",
    "    axarr[1,0].set_xlabel(\"l\")\n",
    "    axarr[1,0].set_ylabel(\"d (pc)\")\n",
    "    \n",
    "    \n",
    "    axarr[0,1].scatter(df[np.where(labels == ilab),3],df[np.where(labels == ilab),4] , s= 0.5, c= df[np.where(labels == ilab),2], cmap=cmap)\n",
    "    axarr[0,1].set_xlabel(\"Vdra\")\n",
    "    axarr[0,1].set_ylabel(\"Vdec\")\n",
    "    \n",
    "    axarr[1,1].scatter(df[np.where(labels == ilab),6],df[np.where(labels == ilab),5] , s = 0.5, c= df[np.where(labels == ilab),2], cmap=cmap)\n",
    "    axarr[1,1].set_xlabel(\"G-R\")\n",
    "    axarr[1,1].set_ylabel(\"G\")\n",
    "    axarr[1,1].set_xlim(-1.,1.5)\n",
    "    axarr[1,1].set_ylim(27.,10)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## astrometric conversion\n",
    "## \n",
    "def convert_to_cartesian(lgal, bga, dist, offCenter = [0., 0.]):\n",
    "    \"Convert ra,dec (ICRS) and distance (pc) to Cartesian reference. Off is the offset in Lgal,Bgal\"\n",
    "    \n",
    "    xx = np.zeros(len(lgal))\n",
    "    yy = np.zeros(len(lgal))\n",
    "    zz = np.zeros(len(lgal))\n",
    "    \n",
    "    lgalOff = lgal - offCenter[0]\n",
    "    bgalOff = bgal - offCenter[1]\n",
    "    \n",
    "    print(offCenter[0])\n",
    "    print(offCenter[1])\n",
    "    print(min(lgalOff))\n",
    "    print(max(lgalOff))\n",
    "    print(min(bgalOff))\n",
    "    print(max(bgalOff))\n",
    "    \n",
    "    \n",
    "    for i in range(len(lgal)):\n",
    "        c = coord.SkyCoord(l=lgalOff[i]*u.degree, b=bgalOff[i]*u.degree, distance=dist[i]*u.pc, frame='galactic')\n",
    "        \n",
    "        xx[i] = c.cartesian.x.value\n",
    "        yy[i] = c.cartesian.y.value\n",
    "        zz[i] = c.cartesian.z.value\n",
    "        \n",
    "    print(\"## XX\")\n",
    "    print(\"min, max: %f , %f\"%(min(xx),max(xx)))\n",
    "    print(\"## YY\")\n",
    "    print(\"min, max: %f , %f\"%(min(yy),max(yy)))\n",
    "    print(\"## ZZ\")\n",
    "    print(\"min, max: %f , %f\"%(min(zz),max(zz)))  \n",
    "        \n",
    "    return(xx,yy,zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Ruprecht 1-2.0deg.vot read...\n",
      "## Total stars: 43294\n",
      "## Conversion done...\n",
      "## Stars selected: 33497\n",
      "## Normalization Normal-Gauss done on filtered data..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read the data and do the conversion\n",
    "\n",
    "\n",
    "source = gu.source(clustername)\n",
    "source.weight = WEIGHT\n",
    "#source.query(RADIUS, errtol = 0.2, dump = True)\n",
    "source.read_votable(voname)\n",
    "source.convert_filter_data(mag_range = [0., 40])\n",
    "source.normalization_normal()\n",
    "#source.normalization_minmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "Metric to quantify goodness-of-solution for the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric1(df, labels, APERTURE = 0.2 , MAXRADIUS = 1. , NBOOTSTRAP =20 ):\n",
    "    \"Using the density contrat assuming the OC is at the center\"\n",
    "    \n",
    "    xc   = np.mean(df[:,0])\n",
    "    yc   = np.mean(df[:,1]) \n",
    "    \n",
    "    nlab = max(labels)+1\n",
    "    aper2 = APERTURE*APERTURE\n",
    "    metric = {}\n",
    "    metric['label'] = []\n",
    "    metric['Q'] = []\n",
    "    metric['Q_err'] = []\n",
    "    \n",
    "    for ilab in range(nlab):\n",
    "        \n",
    "        dflab = df[np.where(labels == ilab),:][0]\n",
    "        radii = (dflab[:,0]- xc)*(dflab[:,0]- xc)+(dflab[:,1]- yc)*(dflab[:,1]- yc)\n",
    "        nclust = radii[np.where(radii < aper2)]\n",
    "        dens_clust = len(nclust) / aper2\n",
    "        \n",
    "        angle_out = np.random.uniform(0., 2*math.pi, NBOOTSTRAP)\n",
    "        rad_out   = np.random.uniform(APERTURE,MAXRADIUS-APERTURE, NBOOTSTRAP)\n",
    "        \n",
    "        Q_c = np.zeros(NBOOTSTRAP)\n",
    "        \n",
    "        for k in range(NBOOTSTRAP): \n",
    "            xi = xc + rad_out[k]*math.cos(angle_out[k])\n",
    "            yi = yc + rad_out[k]*math.sin(angle_out[k])\n",
    "            radii_out = (dflab[:,0]- xi)*(dflab[:,0]- xi)+(dflab[:,1]- yi)*(dflab[:,1]- yi)\n",
    "            nout = radii_out[np.where(radii_out < aper2)]\n",
    "            dens_out_k = max(1,len(nout)) / aper2\n",
    "            Q_c[k] = dens_clust / dens_out_k\n",
    "            \n",
    "        metric['label'].append(ilab)\n",
    "        metric['Q'].append(np.mean(Q_c))\n",
    "        metric['Q_err'].append(np.std(Q_c))\n",
    "        \n",
    "    return(metric)\n",
    "                          \n",
    "    \n",
    "def metric2(df, labels, APERTURE = 0.2 , MAXRADIUS = 1. , NBOOTSTRAP = 50 , SIGCLIP = 0.):\n",
    "    \"Using the density contrat assuming the OC is at the center and the distribution around is regular (no holes)\"\n",
    "        \n",
    "    epsilon = 0.1\n",
    "    xc   = np.mean(df[:,0])\n",
    "    yc   = np.mean(df[:,1]) \n",
    "    \n",
    "    nlab = max(labels)+1\n",
    "    aper2 = APERTURE*APERTURE\n",
    "    metric = {}\n",
    "    metric['label'] = []\n",
    "    metric['Q'] = []\n",
    "    metric['Q_err'] = []\n",
    "    \n",
    "    for ilab in range(nlab):\n",
    "        \n",
    "        dflab = df[np.where(labels == ilab),:][0]\n",
    "        radii = (dflab[:,0]- xc)*(dflab[:,0]- xc)+(dflab[:,1]- yc)*(dflab[:,1]- yc)\n",
    "        nclust = radii[np.where(radii < aper2)]\n",
    "        dens_clust = len(nclust) / aper2\n",
    "        \n",
    "        angle_out = np.random.uniform(0., 2*math.pi, NBOOTSTRAP)\n",
    "        rad_out   = np.random.uniform(APERTURE,MAXRADIUS-APERTURE, NBOOTSTRAP)\n",
    "        \n",
    "        nstarsout = np.zeros(NBOOTSTRAP)\n",
    "        \n",
    "        for k in range(NBOOTSTRAP): \n",
    "            xi = xc + rad_out[k]*math.cos(angle_out[k])\n",
    "            yi = yc + rad_out[k]*math.sin(angle_out[k])\n",
    "            radii_out = (dflab[:,0]- xi)*(dflab[:,0]- xi)+(dflab[:,1]- yi)*(dflab[:,1]- yi)\n",
    "            nout = radii_out[np.where(radii_out < aper2)]\n",
    "            nstarsout[k] = len(nout) + np.random.uniform(1., 1.+ epsilon)\n",
    "                \n",
    "        outmean = np.mean(nstarsout)\n",
    "        outstd  = np.std(nstarsout)\n",
    "        \n",
    "        nstar_filtered = np.where( (nstarsout - outmean)/ outstd > SIGCLIP )\n",
    "\n",
    "        dens_out = nstarsout[nstar_filtered] / aper2\n",
    "        Q_c = np.zeros(len(dens_out))\n",
    "        Q_c = dens_clust / dens_out\n",
    "        \n",
    "        metric['label'].append(ilab)\n",
    "        metric['Q'].append(np.mean(Q_c))\n",
    "        metric['Q_err'].append(np.std(Q_c))\n",
    "        \n",
    "    return(metric)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_parameters(angmin,angmax,dmin,dmax,vmin,vmax,magmin,magmax, kmin, kmax ,ntrial, von = \"test.vot\", radius = 1):\n",
    "    \"Range of the weight for each group of parameters\"\n",
    "        \n",
    "    s = gu.source(clustername)\n",
    "    s.read_votable(von)\n",
    "\n",
    "    metric = {}\n",
    "    angle = np.linspace(angmin,angmax,ntrial)\n",
    "    distance = np.linspace(dmin,dmax,ntrial)\n",
    "    vel   = np.linspace(vmin, vmax,ntrial)\n",
    "    mag   = np.linspace(magmin, magmax,ntrial)\n",
    "    kclus = range(kmin,kmax)\n",
    "    \n",
    "    metric['kmeans'] = {}\n",
    "    metric['kmeans']['weight'] = []\n",
    "    metric['kmeans']['metric'] = []\n",
    "                            \n",
    "                            \n",
    "    for a in angle:\n",
    "        for v in vel:\n",
    "            for m in mag:\n",
    "                for d in distance:\n",
    "                    for k in kclus:\n",
    "                        WEIGHT = [a,a,d,v,v,m,m,m] \n",
    "                        s.weight = WEIGHT\n",
    "                        s.convert_filter_data(mag_range = [0., 40])\n",
    "                        s.normalization_normal()\n",
    "    \n",
    "                        print(WEIGHT)\n",
    "        \n",
    "                        kmeans = cluster.KMeans(n_clusters= kCluster, max_iter = 2000, n_init = 50)\n",
    "                        kmeans.fit(s.dfnorm)\n",
    "                        labels_k = kmeans.labels_\n",
    "                        qk = metric1(s.df, labels_k, APERTURE = 0.2 , MAXRADIUS = radius , NBOOTSTRAP =10 )\n",
    "                        metric['kmeans']['weight'].append(WEIGHT)\n",
    "                        metric['kmeans']['metric'].append(qk)\n",
    "                            \n",
    "        \n",
    "    return(metric)\n",
    "\n",
    "\n",
    "def random_weighting(angmin,angmax,dmin,dmax,vmin,vmax,magmin,magmax, kmin, kmax , von = \"test.vot\", radius = 1, NBOOTSTRAP = 100, SCAN = None):\n",
    "    \"Sample with NBOOTSTRAP trial in the weight range to get the Q\"\n",
    "    \n",
    "    np.random.seed()\n",
    "    \n",
    "    s = gu.source(clustername)\n",
    "    s.read_votable(von)\n",
    "    \n",
    "    aper = 0.5\n",
    "    \n",
    "    if SCAN == None:\n",
    "        metric = {}\n",
    "        metric['kmeans'] = {}\n",
    "        metric['kmeans']['weight'] = []\n",
    "        metric['kmeans']['metric'] = []\n",
    "        metric['ward'] = {}\n",
    "        metric['ward']['weight'] = []\n",
    "        metric['ward']['metric'] = []\n",
    "        metric['spectral'] = {}\n",
    "        metric['spectral']['weight'] = []\n",
    "        metric['spectral']['metric'] = []\n",
    "        metric['dbscan'] = {}\n",
    "        metric['dbscan']['weight'] = []\n",
    "        metric['dbscan']['metric'] = []\n",
    "    else:\n",
    "        metric = SCAN\n",
    "        \n",
    "    \n",
    "    angle     = np.random.uniform(angmin, angmax, NBOOTSTRAP)\n",
    "    distance  = np.random.uniform(dmin, dmax, NBOOTSTRAP)\n",
    "    velocity  = np.random.uniform(vmin, vmax, NBOOTSTRAP)\n",
    "    magnitude = np.random.uniform(magmin, magmax, NBOOTSTRAP)\n",
    "    ncluster  = np.random.randint(kmin, kmax, NBOOTSTRAP)\n",
    "    \n",
    "            \n",
    "    for i in range(NBOOTSTRAP):\n",
    "        WEIGHT = [angle[i],angle[i],distance[i],velocity[i],velocity[i], magnitude[i],magnitude[i], magnitude[i]]\n",
    "        nclust = ncluster[i]\n",
    "        \n",
    "        s.weight = WEIGHT\n",
    "        s.convert_filter_data(mag_range = [0., 40])\n",
    "        s.normalization_normal()\n",
    "    \n",
    "        print(WEIGHT)\n",
    "        print(i)\n",
    "        \n",
    "        # kmeans\n",
    "        kmeans = cluster.KMeans(n_clusters= nclust, max_iter = 2000, n_init = 50)\n",
    "        kmeans.fit(s.dfnorm)\n",
    "        labels_k = kmeans.labels_\n",
    "        qk = metric2(s.df, labels_k, APERTURE = aper , MAXRADIUS = 0.9 * radius , NBOOTSTRAP =50 )\n",
    "        metric['kmeans']['weight'].append(WEIGHT)\n",
    "        metric['kmeans']['metric'].append(qk)\n",
    "        print(\"## Best Q: %3.1f\"%(max(qk['Q'])))\n",
    "        print(\"# k-means done\")\n",
    "                            \n",
    "        # ward\n",
    "        connectivity = kneighbors_graph(source.dfnorm, n_neighbors= neighbors, include_self=False)\n",
    "        # make connectivity symmetric\n",
    "        connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "        ward = cluster.AgglomerativeClustering(n_clusters= nclust, linkage='ward', connectivity=connectivity)\n",
    "        ward.fit(s.dfnorm)\n",
    "        labels_w = ward.labels_\n",
    "        qw = metric2(s.df, labels_w, APERTURE = aper , MAXRADIUS = 0.9 * radius , NBOOTSTRAP =50 )\n",
    "        metric['ward']['weight'].append(WEIGHT)\n",
    "        metric['ward']['metric'].append(qw)\n",
    "        print(\"## Best Q: %3.1f\"%(max(qw['Q'])))        \n",
    "        print(\"# Ward done\")\n",
    "        \n",
    "        # Spectral\n",
    "        spectral = cluster.SpectralClustering(n_clusters = nclust, eigen_solver='arpack', affinity=\"nearest_neighbors\")\n",
    "        # spectral.fit(s.dfnorm) !!!!\n",
    "        # !!!!!!\n",
    "        print(\"# !!! Spectral = Ward\")\n",
    "        labels_s = ward.labels_\n",
    "        #!!!!!!!\n",
    "        qs = metric2(s.df, labels_s, APERTURE = aper , MAXRADIUS = 0.9 * radius , NBOOTSTRAP =50 )\n",
    "        metric['spectral']['weight'].append(WEIGHT)\n",
    "        metric['spectral']['metric'].append(qs)\n",
    "        print(\"## Best Q: %3.1f\"%(max(qs['Q'])))        \n",
    "        print(\"# Spectral done\")\n",
    "        \n",
    "        # DBSCAN\n",
    "        dbscan = cluster.DBSCAN(eps = eps, min_samples = min_samples)\n",
    "        dbscan.fit(s.dfnorm)\n",
    "        labels_d = dbscan.labels_\n",
    "        unique_labels = set(labels_d)\n",
    "        print(unique_labels)\n",
    "        n_clusters_ = len(set(labels_d)) - (1 if -1 in labels_d else 0)\n",
    "        if n_clusters_ > 0:\n",
    "            qd = metric2(s.df, labels_d, APERTURE = aper , MAXRADIUS = 0.9 * radius , NBOOTSTRAP =50 )\n",
    "        else:\n",
    "            qd['Q'] = [0., 0.]\n",
    "            qd['Q_err'] = [0.,0.]\n",
    "            qd['label'] = [0,1]\n",
    "\n",
    "        metric['dbscan']['weight'].append(WEIGHT)\n",
    "        metric['dbscan']['metric'].append(qd)\n",
    "        print(\"## Best Q: %3.1f\"%(max(qd['Q'])))\n",
    "        print(\"# DBSCAN done\")\n",
    "            \n",
    "    return(metric)       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Ruprecht 1-2.0deg.vot read...\n",
      "## Total stars: 43294\n",
      "## Conversion done...\n",
      "## Stars selected: 33497\n",
      "## Normalization Normal-Gauss done on filtered data..\n",
      "[4.954659412540897, 4.954659412540897, 9.142301280465396, 5.951293492730634, 5.951293492730634, 3.451328616340862, 3.451328616340862, 3.451328616340862]\n",
      "0\n",
      "## Best Q: 1.1\n",
      "# k-means done\n",
      "## Best Q: 1.0\n",
      "# Ward done\n",
      "# !!! Spectral = Ward\n",
      "## Best Q: 1.0\n",
      "# Spectral done\n",
      "{-1}\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'qd' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-60c626877280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# q = iter_parameters(2.,5.,7.,12.,2.,4.,1.,3., 7,8 ,2, von = voname, radius = 2.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m q = random_weighting(1.,7.,3.,15.,1.,7.,1.,5., 5 ,12 , von = voname, radius = 2., NBOOTSTRAP = 1000, \n\u001b[0;32m----> 9\u001b[0;31m                      SCAN = None)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataQran.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-dab0a0e53c5c>\u001b[0m in \u001b[0;36mrandom_weighting\u001b[0;34m(angmin, angmax, dmin, dmax, vmin, vmax, magmin, magmax, kmin, kmax, von, radius, NBOOTSTRAP, SCAN)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dbscan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dbscan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"## Best Q: %3.1f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# DBSCAN done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'qd' referenced before assignment"
     ]
    }
   ],
   "source": [
    "## testing loop on parameters ..\n",
    "## Could be very long!!!\n",
    "## To continue a previous scan..\n",
    "#with open('dataQran.pickle', 'rb') as f:\n",
    "#    previousMetric = pickle.load(f)\n",
    "\n",
    "# q = iter_parameters(2.,5.,7.,12.,2.,4.,1.,3., 7,8 ,2, von = voname, radius = 2.)\n",
    "q = random_weighting(1.,7.,3.,15.,1.,7.,1.,5., 5 ,12 , von = voname, radius = 2., NBOOTSTRAP = 1000, \n",
    "                     SCAN = None)\n",
    "\n",
    "with open('dataQran.pickle', 'wb') as f:\n",
    "    pickle.dump(q, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"## k-means...\")\n",
    "\n",
    "# KMeans for each normalisation\n",
    "kmeans = cluster.KMeans(n_clusters= kCluster, max_iter = 2000, n_init = 50)\n",
    "kmeans.fit(source.dfnorm)\n",
    "labels_k = kmeans.labels_\n",
    "for i in range(kCluster):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_k[np.where(labels_k == i)]), np.median(source.df[np.where(labels_k == i),2]), np.std(source.df[np.where(labels_k == i),2])))\n",
    "print(\"##\")\n",
    "\n",
    "###########\n",
    "print(\"## Ward... \")\n",
    "# connectivity matrix for structured Ward\n",
    "\n",
    "connectivity = kneighbors_graph(source.dfnorm, n_neighbors= neighbors, include_self=False)\n",
    "# make connectivity symmetric\n",
    "connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "ward = cluster.AgglomerativeClustering(n_clusters= kCluster, linkage='ward', connectivity=connectivity)\n",
    "ward.fit(source.dfnorm)\n",
    "labels_w = ward.labels_\n",
    "for i in range(kCluster):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_w[np.where(labels_w == i)]), np.median(source.df[np.where(labels_w == i),2]),np.std(source.df[np.where(labels_w == i),2])))\n",
    "print(\"##\")\n",
    "    \n",
    "############# \n",
    "print(\"## Spectral...\")\n",
    "spectral = cluster.SpectralClustering(n_clusters = kCluster, eigen_solver='arpack', affinity=\"nearest_neighbors\")\n",
    "spectral.fit(source.dfnorm)\n",
    "labels_s = spectral.labels_\n",
    "for i in range(kCluster):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_s[np.where(labels_s == i)]), np.median(source.df[np.where(labels_s == i),2]),np.std(source.df[np.where(labels_s == i),2])))\n",
    "print(\"##\")\n",
    "\n",
    "\n",
    "############# \n",
    "print(\"## DBSCAN...\")\n",
    "dbscan = cluster.DBSCAN(eps, min_samples)\n",
    "dbscan.fit(source.dfnorm)\n",
    "labels_d = dbscan.labels_\n",
    "unique_labels = set(labels_d)\n",
    "print(unique_labels)\n",
    "for i in range(max(labels_d)+1):\n",
    "    print(\"# Label %5d : %5d  Dist: %6.1f (%5.1f)\"%(i,len(labels_d[np.where(labels_d == i)]), np.median(source.df[np.where(labels_d == i),2]), np.std(source.df[np.where(labels_d == i),2]) ))\n",
    "print(\"##\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Metrics of the solutions\n",
    "np.random.seed(0)\n",
    "labs = labels_k\n",
    "qk = metric2(source.df, labs , APERTURE = 0.5 , MAXRADIUS = 0.9 * RADIUS, SIGCLIP = 0.0) \n",
    "labs = labels_w\n",
    "qw = metric2(source.df, labs , APERTURE = 0.5 , MAXRADIUS = 0.9 * RADIUS, SIGCLIP = 0.0) \n",
    "labs = labels_s\n",
    "qs = metric2(source.df, labs , APERTURE = 0.5 , MAXRADIUS = 0.9 * RADIUS, SIGCLIP = 0.0) \n",
    "labs = labels_d\n",
    "qd = metric2(source.df, labs , APERTURE = 0.5 , MAXRADIUS = 0.9 * RADIUS, SIGCLIP = 0.0)  \n",
    "\n",
    "plt.yscale(\"log\", nonposy='clip')\n",
    "plt.xlim([-1,kCluster+1])\n",
    "plt.errorbar(qk['label'],qk['Q'], qk['Q_err'], label='k-means',fmt='.k', ecolor='gray', lw=1, capsize=5)\n",
    "plt.errorbar(qw['label'],qw['Q'], qw['Q_err'], label='Ward', fmt='*r', ecolor='gray', lw=1, capsize=5)\n",
    "plt.errorbar(qs['label'],qs['Q'], qs['Q_err'], label='Spectral', fmt='Db', ecolor='gray', lw=1, capsize=5)\n",
    "plt.errorbar(qd['label'],qd['Q'], qd['Q_err'], label='DBSCAN', fmt='og', ecolor='gray', lw=1, capsize=5)\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.xlabel(\"Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## separation distance\n",
    "angl2pc = 3600. * 150e6 * distclust / 3.1e13\n",
    "print(\"## Angular distance (1deg) : %3.1f pc\"%(angl2pc))\n",
    "plot2d(source.df, labels_d,0, cmap = \"hsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
